{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# About\n",
    "\n",
    "In this programming assignment you will train a classifier to identify type of a particle. There are six particle types: electron, proton, muon, kaon, pion and ghost. Ghost is a particle with other type than the first five or a detector noise. \n",
    "\n",
    "Different particle types remain different responses in the detector systems or subdetectors. Thre are five systems: tracking system, ring imaging Cherenkov detector (RICH), electromagnetic and hadron calorimeters, and muon system.\n",
    "\n",
    "![pid](pic/pid.jpg)\n",
    "\n",
    "You task is to identify a particle type using the responses in the detector systems. \n",
    "\n",
    "# Attention\n",
    "\n",
    "Data files you should download from https://github.com/hse-aml/hadron-collider-machine-learning/releases/tag/Week_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas\n",
    "import numpy\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import log_loss\n",
    "import utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download data\n",
    "\n",
    "Download data used to train classifiers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read training file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pandas.read_csv('training.csv.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TrackP</th>\n",
       "      <th>TrackNDoFSubdetector2</th>\n",
       "      <th>BremDLLbeElectron</th>\n",
       "      <th>MuonLooseFlag</th>\n",
       "      <th>FlagSpd</th>\n",
       "      <th>SpdE</th>\n",
       "      <th>EcalDLLbeElectron</th>\n",
       "      <th>DLLmuon</th>\n",
       "      <th>RICHpFlagElectron</th>\n",
       "      <th>EcalDLLbeMuon</th>\n",
       "      <th>...</th>\n",
       "      <th>TrackNDoF</th>\n",
       "      <th>RICHpFlagMuon</th>\n",
       "      <th>RICH_DLLbeKaon</th>\n",
       "      <th>RICH_DLLbeElectron</th>\n",
       "      <th>HcalE</th>\n",
       "      <th>MuonFlag</th>\n",
       "      <th>FlagMuon</th>\n",
       "      <th>PrsE</th>\n",
       "      <th>RICH_DLLbeMuon</th>\n",
       "      <th>RICH_DLLbeProton</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>74791.156263</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.232275</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.2</td>\n",
       "      <td>-2.505719</td>\n",
       "      <td>6.604153</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.929960</td>\n",
       "      <td>...</td>\n",
       "      <td>28.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-7.213300</td>\n",
       "      <td>-0.280200</td>\n",
       "      <td>5586.589846</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.422315</td>\n",
       "      <td>-2.081143e-07</td>\n",
       "      <td>-24.824400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2738.489989</td>\n",
       "      <td>15.0</td>\n",
       "      <td>-0.357748</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.864351</td>\n",
       "      <td>0.263651</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-2.061959</td>\n",
       "      <td>...</td>\n",
       "      <td>32.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.324317</td>\n",
       "      <td>1.707283</td>\n",
       "      <td>-0.000007</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>43.334935</td>\n",
       "      <td>2.771583e+00</td>\n",
       "      <td>-0.648017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2161.409908</td>\n",
       "      <td>17.0</td>\n",
       "      <td>-999.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.000000</td>\n",
       "      <td>-999.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-999.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-999.000000</td>\n",
       "      <td>-999.000000</td>\n",
       "      <td>-999.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-999.000000</td>\n",
       "      <td>-9.990000e+02</td>\n",
       "      <td>-999.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>15277.730490</td>\n",
       "      <td>20.0</td>\n",
       "      <td>-0.638984</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.2</td>\n",
       "      <td>-2.533918</td>\n",
       "      <td>-8.724949</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-3.253981</td>\n",
       "      <td>...</td>\n",
       "      <td>36.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-35.202221</td>\n",
       "      <td>-14.742319</td>\n",
       "      <td>4482.803707</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.194175</td>\n",
       "      <td>-3.070819e+00</td>\n",
       "      <td>-29.291519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7563.700195</td>\n",
       "      <td>19.0</td>\n",
       "      <td>-0.638962</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.2</td>\n",
       "      <td>-2.087146</td>\n",
       "      <td>-7.060422</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.995816</td>\n",
       "      <td>...</td>\n",
       "      <td>33.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>25.084287</td>\n",
       "      <td>-10.272412</td>\n",
       "      <td>5107.554680</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>-5.373712e+00</td>\n",
       "      <td>23.653087</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 50 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         TrackP  TrackNDoFSubdetector2  BremDLLbeElectron  MuonLooseFlag  \\\n",
       "0  74791.156263                   15.0           0.232275            1.0   \n",
       "1   2738.489989                   15.0          -0.357748            0.0   \n",
       "2   2161.409908                   17.0        -999.000000            0.0   \n",
       "3  15277.730490                   20.0          -0.638984            0.0   \n",
       "4   7563.700195                   19.0          -0.638962            0.0   \n",
       "\n",
       "   FlagSpd   SpdE  EcalDLLbeElectron     DLLmuon  RICHpFlagElectron  \\\n",
       "0      1.0    3.2          -2.505719    6.604153                1.0   \n",
       "1      1.0    3.2           1.864351    0.263651                1.0   \n",
       "2      0.0 -999.0        -999.000000 -999.000000                0.0   \n",
       "3      1.0    3.2          -2.533918   -8.724949                1.0   \n",
       "4      1.0    3.2          -2.087146   -7.060422                1.0   \n",
       "\n",
       "   EcalDLLbeMuon  ...  TrackNDoF  RICHpFlagMuon  RICH_DLLbeKaon  \\\n",
       "0       1.929960  ...       28.0            1.0       -7.213300   \n",
       "1      -2.061959  ...       32.0            1.0       -0.324317   \n",
       "2    -999.000000  ...       27.0            0.0     -999.000000   \n",
       "3      -3.253981  ...       36.0            1.0      -35.202221   \n",
       "4      -0.995816  ...       33.0            1.0       25.084287   \n",
       "\n",
       "   RICH_DLLbeElectron        HcalE  MuonFlag  FlagMuon        PrsE  \\\n",
       "0           -0.280200  5586.589846       1.0       1.0   10.422315   \n",
       "1            1.707283    -0.000007       0.0       1.0   43.334935   \n",
       "2         -999.000000  -999.000000       0.0       0.0 -999.000000   \n",
       "3          -14.742319  4482.803707       0.0       1.0    2.194175   \n",
       "4          -10.272412  5107.554680       0.0       1.0    0.000015   \n",
       "\n",
       "   RICH_DLLbeMuon  RICH_DLLbeProton  \n",
       "0   -2.081143e-07        -24.824400  \n",
       "1    2.771583e+00         -0.648017  \n",
       "2   -9.990000e+02       -999.000000  \n",
       "3   -3.070819e+00        -29.291519  \n",
       "4   -5.373712e+00         23.653087  \n",
       "\n",
       "[5 rows x 50 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### List of columns in the samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, **Spd** stands for Scintillating Pad Detector, **Prs** - Preshower, **Ecal** - electromagnetic calorimeter, **Hcal** - hadronic calorimeter, **Brem** denotes traces of the particles that were deflected by detector."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ID - id value for tracks (presents only in the test file for the submitting purposes)\n",
    "- Label - string valued observable denoting particle types. Can take values \"Electron\", \"Muon\", \"Kaon\", \"Proton\", \"Pion\" and \"Ghost\". This column is absent in the test file.\n",
    "- FlagSpd - flag (0 or 1), if reconstructed track passes through Spd\n",
    "- FlagPrs - flag (0 or 1), if reconstructed track passes through Prs\n",
    "- FlagBrem - flag (0 or 1), if reconstructed track passes through Brem\n",
    "- FlagEcal - flag (0 or 1), if reconstructed track passes through Ecal\n",
    "- FlagHcal - flag (0 or 1), if reconstructed track passes through Hcal\n",
    "- FlagRICH1 - flag (0 or 1), if reconstructed track passes through the first RICH detector\n",
    "- FlagRICH2 - flag (0 or 1), if reconstructed track passes through the second RICH detector\n",
    "- FlagMuon - flag (0 or 1), if reconstructed track passes through muon stations (Muon)\n",
    "- SpdE - energy deposit associated to the track in the Spd\n",
    "- PrsE - energy deposit associated to the track in the Prs\n",
    "- EcalE - energy deposit associated to the track in the Hcal\n",
    "- HcalE - energy deposit associated to the track in the Hcal\n",
    "- PrsDLLbeElectron - delta log-likelihood for a particle candidate to be electron using information from Prs\n",
    "- BremDLLbeElectron - delta log-likelihood for a particle candidate to be electron using information from Brem\n",
    "- TrackP - particle momentum\n",
    "- TrackPt - particle transverse momentum\n",
    "- TrackNDoFSubdetector1  - number of degrees of freedom for track fit using hits in the tracking sub-detector1\n",
    "- TrackQualitySubdetector1 - chi2 quality of the track fit using hits in the tracking sub-detector1\n",
    "- TrackNDoFSubdetector2 - number of degrees of freedom for track fit using hits in the tracking sub-detector2\n",
    "- TrackQualitySubdetector2 - chi2 quality of the track fit using hits in the  tracking sub-detector2\n",
    "- TrackNDoF - number of degrees of freedom for track fit using hits in all tracking sub-detectors\n",
    "- TrackQualityPerNDoF - chi2 quality of the track fit per degree of freedom\n",
    "- TrackDistanceToZ - distance between track and z-axis (beam axis)\n",
    "- Calo2dFitQuality - quality of the 2d fit of the clusters in the calorimeter \n",
    "- Calo3dFitQuality - quality of the 3d fit in the calorimeter with assumption that particle was electron\n",
    "- EcalDLLbeElectron - delta log-likelihood for a particle candidate to be electron using information from Ecal\n",
    "- EcalDLLbeMuon - delta log-likelihood for a particle candidate to be muon using information from Ecal\n",
    "- EcalShowerLongitudinalParameter - longitudinal parameter of Ecal shower\n",
    "- HcalDLLbeElectron - delta log-likelihood for a particle candidate to be electron using information from Hcal\n",
    "- HcalDLLbeMuon - delta log-likelihood for a particle candidate to be using information from Hcal\n",
    "- RICHpFlagElectron - flag (0 or 1) if momentum is greater than threshold for electrons to produce Cherenkov light\n",
    "- RICHpFlagProton - flag (0 or 1) if momentum is greater than threshold for protons to produce Cherenkov light\n",
    "- RICHpFlagPion - flag (0 or 1) if momentum is greater than threshold for pions to produce Cherenkov light\n",
    "- RICHpFlagKaon - flag (0 or 1) if momentum is greater than threshold for kaons to produce Cherenkov light\n",
    "- RICHpFlagMuon - flag (0 or 1) if momentum is greater than threshold for muons to produce Cherenkov light\n",
    "- RICH_DLLbeBCK  - delta log-likelihood for a particle candidate to be background using information from RICH\n",
    "- RICH_DLLbeKaon - delta log-likelihood for a particle candidate to be kaon using information from RICH\n",
    "- RICH_DLLbeElectron - delta log-likelihood for a particle candidate to be electron using information from RICH\n",
    "- RICH_DLLbeMuon - delta log-likelihood for a particle candidate to be muon using information from RICH\n",
    "- RICH_DLLbeProton - delta log-likelihood for a particle candidate to be proton using information from RICH\n",
    "- MuonFlag - muon flag (is this track muon) which is determined from muon stations\n",
    "- MuonLooseFlag muon flag (is this track muon) which is determined from muon stations using looser criteria\n",
    "- MuonLLbeBCK - log-likelihood for a particle candidate to be not muon using information from muon stations\n",
    "- MuonLLbeMuon - log-likelihood for a particle candidate to be muon using information from muon stations\n",
    "- DLLelectron - delta log-likelihood for a particle candidate to be electron using information from all subdetectors\n",
    "- DLLmuon - delta log-likelihood for a particle candidate to be muon using information from all subdetectors\n",
    "- DLLkaon - delta log-likelihood for a particle candidate to be kaon using information from all subdetectors\n",
    "- DLLproton - delta log-likelihood for a particle candidate to be proton using information from all subdetectors\n",
    "- GhostProbability - probability for a particle candidate to be ghost track. This variable is an output of classification model used in the tracking algorithm."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Delta log-likelihood in the features descriptions means the difference between log-likelihood for the mass hypothesis that a given track is left by some particle (for example, electron) and log-likelihood for the mass hypothesis that a given track is left by a pion (so, DLLpion = 0 and thus we don't have these columns). This is done since most tracks (~80%) are left by pions and in practice we actually need to discriminate other particles from pions. In other words, the null hypothesis is that particle is a pion."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Look at the labels set\n",
    "\n",
    "The training data contains six classes. Each class corresponds to a particle type. Your task is to predict type of a particle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Electron', 'Ghost', 'Kaon', 'Muon', 'Pion', 'Proton'}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(data.Label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert the particle types into class numbers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0, 1, 2, 3, 4, 5}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['Class'] = utils.get_class_ids(data.Label.values)\n",
    "set(data.Class)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define training features\n",
    "\n",
    "The following set of features describe particle responses in the detector systems:\n",
    "\n",
    "![features](pic/features.jpeg)\n",
    "\n",
    "Also there are several combined features. The full list is following."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['BremDLLbeElectron',\n",
       " 'PrsDLLbeElectron',\n",
       " 'RICH_DLLbeBCK',\n",
       " 'FlagMuon',\n",
       " 'RICHpFlagKaon',\n",
       " 'TrackQualitySubdetector1',\n",
       " 'FlagRICH2',\n",
       " 'TrackP',\n",
       " 'RICH_DLLbeProton',\n",
       " 'TrackNDoFSubdetector2',\n",
       " 'FlagHcal',\n",
       " 'EcalShowerLongitudinalParameter',\n",
       " 'MuonLooseFlag',\n",
       " 'EcalDLLbeMuon',\n",
       " 'RICHpFlagProton',\n",
       " 'MuonLLbeBCK',\n",
       " 'FlagEcal',\n",
       " 'RICH_DLLbeKaon',\n",
       " 'RICHpFlagMuon',\n",
       " 'TrackPt',\n",
       " 'HcalDLLbeElectron',\n",
       " 'EcalDLLbeElectron',\n",
       " 'RICHpFlagPion',\n",
       " 'RICH_DLLbeElectron',\n",
       " 'TrackDistanceToZ',\n",
       " 'Calo2dFitQuality',\n",
       " 'TrackNDoF',\n",
       " 'GhostProbability',\n",
       " 'RICH_DLLbeMuon',\n",
       " 'TrackQualitySubdetector2',\n",
       " 'FlagPrs',\n",
       " 'DLLkaon',\n",
       " 'EcalE',\n",
       " 'MuonLLbeMuon',\n",
       " 'FlagBrem',\n",
       " 'MuonFlag',\n",
       " 'Calo3dFitQuality',\n",
       " 'DLLelectron',\n",
       " 'DLLmuon',\n",
       " 'FlagRICH1',\n",
       " 'FlagSpd',\n",
       " 'HcalDLLbeMuon',\n",
       " 'PrsE',\n",
       " 'TrackNDoFSubdetector1',\n",
       " 'DLLproton',\n",
       " 'HcalE',\n",
       " 'RICHpFlagElectron',\n",
       " 'TrackQualityPerNDoF',\n",
       " 'SpdE']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features = list(set(data.columns) - {'Label', 'Class'})\n",
    "features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Divide training data into 2 parts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data, validation_data = train_test_split(data, random_state=11, train_size=0.90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1080000, 120000)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(training_data), len(validation_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "training_scale = scaler.fit_transform(training_data[features].values)\n",
    "validation_scale = scaler.transform(validation_data[features].values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sklearn classifier\n",
    "\n",
    "On this step your task is to train **Sklearn** classifier to provide lower **log loss** value.\n",
    "\n",
    "\n",
    "TASK: your task is to tune the classifier parameters to achieve the lowest **log loss** value on the validation sample you can."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.ensemble import GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gb = GradientBoostingClassifier(learning_rate=0.05, n_estimators=50, subsample=0.3, random_state=13,\n",
    "#                                 min_samples_leaf=10, max_depth=30)\n",
    "# gb.fit(training_data[features].values, training_data.Class.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Log loss on the cross validation sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # predict each track\n",
    "# proba_gb = gb.predict_proba(validation_data[features].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# log_loss(validation_data.Class.values, proba_gb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keras neural network\n",
    "\n",
    "On this step your task is to train **Keras** NN classifier to provide lower **log loss** value.\n",
    "\n",
    "\n",
    "TASK: your task is to tune the classifier parameters to achieve the lowest **log loss** value on the validation sample you can. Data preprocessing may help you to improve your score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import Dense, Activation\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from keras.utils import np_utils\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nn_model(input_dim):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(100, input_dim=input_dim))\n",
    "    model.add(Activation('relu'))\n",
    "    \n",
    "    model.add(Dense(50))\n",
    "    model.add(Activation('relu'))\n",
    "\n",
    "    model.add(Dense(6))\n",
    "    model.add(Activation('softmax'))\n",
    "\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=Adam())\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "\n",
    "# callback = [EarlyStopping(monitor='val_loss', min_delta=0, patience=4, verbose=0, mode='auto')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1080000 samples, validate on 120000 samples\n",
      "Epoch 1/50\n",
      "1080000/1080000 [==============================] - 20s 19us/sample - loss: 0.7068 - val_loss: 0.6326\n",
      "Epoch 2/50\n",
      "1080000/1080000 [==============================] - 19s 18us/sample - loss: 0.6207 - val_loss: 0.6141\n",
      "Epoch 3/50\n",
      "1080000/1080000 [==============================] - 18s 17us/sample - loss: 0.6055 - val_loss: 0.5982\n",
      "Epoch 4/50\n",
      "1080000/1080000 [==============================] - 18s 17us/sample - loss: 0.5969 - val_loss: 0.5957\n",
      "Epoch 5/50\n",
      "1080000/1080000 [==============================] - 20s 19us/sample - loss: 0.5919 - val_loss: 0.5906\n",
      "Epoch 6/50\n",
      "1080000/1080000 [==============================] - 19s 17us/sample - loss: 0.5874 - val_loss: 0.5859\n",
      "Epoch 7/50\n",
      "1080000/1080000 [==============================] - 18s 17us/sample - loss: 0.5840 - val_loss: 0.5823\n",
      "Epoch 8/50\n",
      "1080000/1080000 [==============================] - 18s 17us/sample - loss: 0.5814 - val_loss: 0.5818\n",
      "Epoch 9/50\n",
      "1080000/1080000 [==============================] - 18s 17us/sample - loss: 0.5792 - val_loss: 0.5799\n",
      "Epoch 10/50\n",
      "1080000/1080000 [==============================] - 19s 18us/sample - loss: 0.5775 - val_loss: 0.5793\n",
      "Epoch 11/50\n",
      "1080000/1080000 [==============================] - 21s 19us/sample - loss: 0.5760 - val_loss: 0.5731\n",
      "Epoch 12/50\n",
      "1080000/1080000 [==============================] - 28s 26us/sample - loss: 0.5746 - val_loss: 0.5762\n",
      "Epoch 13/50\n",
      "1080000/1080000 [==============================] - 17s 16us/sample - loss: 0.5739 - val_loss: 0.5756\n",
      "Epoch 14/50\n",
      "1080000/1080000 [==============================] - 16s 15us/sample - loss: 0.5727 - val_loss: 0.5749\n",
      "Epoch 15/50\n",
      "1080000/1080000 [==============================] - 17s 15us/sample - loss: 0.5716 - val_loss: 0.5753\n",
      "Epoch 16/50\n",
      "1080000/1080000 [==============================] - 17s 16us/sample - loss: 0.5710 - val_loss: 0.5781\n",
      "Epoch 17/50\n",
      "1080000/1080000 [==============================] - 21s 20us/sample - loss: 0.5701 - val_loss: 0.5731\n",
      "Epoch 18/50\n",
      "1080000/1080000 [==============================] - 22s 20us/sample - loss: 0.5694 - val_loss: 0.5745\n",
      "Epoch 19/50\n",
      "1080000/1080000 [==============================] - 16s 15us/sample - loss: 0.5687 - val_loss: 0.5746\n",
      "Epoch 20/50\n",
      "1080000/1080000 [==============================] - 18s 17us/sample - loss: 0.5681 - val_loss: 0.5719\n",
      "Epoch 21/50\n",
      "1080000/1080000 [==============================] - 16s 15us/sample - loss: 0.5678 - val_loss: 0.5730\n",
      "Epoch 22/50\n",
      "1080000/1080000 [==============================] - 17s 16us/sample - loss: 0.5671 - val_loss: 0.5761\n",
      "Epoch 23/50\n",
      "1080000/1080000 [==============================] - 17s 15us/sample - loss: 0.5667 - val_loss: 0.5696\n",
      "Epoch 24/50\n",
      "1080000/1080000 [==============================] - 16s 15us/sample - loss: 0.5662 - val_loss: 0.5696\n",
      "Epoch 25/50\n",
      "1080000/1080000 [==============================] - 16s 15us/sample - loss: 0.5658 - val_loss: 0.5712\n",
      "Epoch 26/50\n",
      "1080000/1080000 [==============================] - 16s 15us/sample - loss: 0.5654 - val_loss: 0.5688\n",
      "Epoch 27/50\n",
      "1080000/1080000 [==============================] - 17s 15us/sample - loss: 0.5649 - val_loss: 0.5678\n",
      "Epoch 28/50\n",
      "1080000/1080000 [==============================] - 16s 15us/sample - loss: 0.5645 - val_loss: 0.5681\n",
      "Epoch 29/50\n",
      "1080000/1080000 [==============================] - 18s 16us/sample - loss: 0.5641 - val_loss: 0.5675\n",
      "Epoch 30/50\n",
      "1080000/1080000 [==============================] - 16s 15us/sample - loss: 0.5638 - val_loss: 0.5661\n",
      "Epoch 31/50\n",
      "1080000/1080000 [==============================] - 19s 18us/sample - loss: 0.5638 - val_loss: 0.5681\n",
      "Epoch 32/50\n",
      "1080000/1080000 [==============================] - 16s 15us/sample - loss: 0.5632 - val_loss: 0.5660\n",
      "Epoch 33/50\n",
      "1080000/1080000 [==============================] - 16s 15us/sample - loss: 0.5630 - val_loss: 0.5681\n",
      "Epoch 34/50\n",
      "1080000/1080000 [==============================] - 16s 15us/sample - loss: 0.5627 - val_loss: 0.5681\n",
      "Epoch 35/50\n",
      "1080000/1080000 [==============================] - 16s 15us/sample - loss: 0.5627 - val_loss: 0.5678\n",
      "Epoch 36/50\n",
      "1080000/1080000 [==============================] - 16s 15us/sample - loss: 0.5622 - val_loss: 0.5668\n",
      "Epoch 37/50\n",
      "1080000/1080000 [==============================] - 17s 15us/sample - loss: 0.5621 - val_loss: 0.5687\n",
      "Epoch 38/50\n",
      "1080000/1080000 [==============================] - 16s 15us/sample - loss: 0.5618 - val_loss: 0.5687\n",
      "Epoch 39/50\n",
      "1080000/1080000 [==============================] - 17s 15us/sample - loss: 0.5617 - val_loss: 0.5650\n",
      "Epoch 40/50\n",
      "1080000/1080000 [==============================] - 16s 15us/sample - loss: 0.5613 - val_loss: 0.5649\n",
      "Epoch 41/50\n",
      "1080000/1080000 [==============================] - 17s 16us/sample - loss: 0.5612 - val_loss: 0.5653\n",
      "Epoch 42/50\n",
      "1080000/1080000 [==============================] - 21s 19us/sample - loss: 0.5608 - val_loss: 0.5664\n",
      "Epoch 43/50\n",
      "1080000/1080000 [==============================] - 16s 15us/sample - loss: 0.5608 - val_loss: 0.5675\n",
      "Epoch 44/50\n",
      "1080000/1080000 [==============================] - 16s 15us/sample - loss: 0.5605 - val_loss: 0.5643\n",
      "Epoch 45/50\n",
      "1080000/1080000 [==============================] - 16s 15us/sample - loss: 0.5604 - val_loss: 0.5655\n",
      "Epoch 46/50\n",
      "1080000/1080000 [==============================] - 16s 15us/sample - loss: 0.5604 - val_loss: 0.5651\n",
      "Epoch 47/50\n",
      "1080000/1080000 [==============================] - 16s 15us/sample - loss: 0.5599 - val_loss: 0.5672\n",
      "Epoch 48/50\n",
      "1080000/1080000 [==============================] - 16s 15us/sample - loss: 0.5598 - val_loss: 0.5642\n",
      "Epoch 49/50\n",
      "1080000/1080000 [==============================] - 16s 15us/sample - loss: 0.5599 - val_loss: 0.5649\n",
      "Epoch 50/50\n",
      "1080000/1080000 [==============================] - 17s 15us/sample - loss: 0.5596 - val_loss: 0.5634\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1f28c11c208>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn = nn_model(len(features))\n",
    "nn.fit(training_scale, np_utils.to_categorical(training_data.Class.values),\n",
    "       validation_data=(validation_scale, np_utils.to_categorical(validation_data.Class.values)),\n",
    "       epochs=50, verbose=1, batch_size=256)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Log loss on the cross validation sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict each track\n",
    "proba_nn = nn.predict_proba(validation_scale)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5633565366016223"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_loss(validation_data.Class.values, proba_nn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quality metrics\n",
    "\n",
    "Plot ROC curves and signal efficiency dependece from particle mometum and transverse momentum values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'proba_gb' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-20-c6d1c003b09d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mproba\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mproba_gb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'proba_gb' is not defined"
     ]
    }
   ],
   "source": [
    "proba = proba_gb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.plot_roc_curves(proba, validation_data.Class.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.plot_signal_efficiency_on_p(proba, validation_data.Class.values, validation_data.TrackP.values, 60, 50)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.plot_signal_efficiency_on_pt(proba, validation_data.Class.values, validation_data.TrackPt.values, 60, 50)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare submission\n",
    "\n",
    "Select your best classifier and prepare submission file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pandas.read_csv('test.csv.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_scale = scaler.transform(test[features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict test sample\n",
    "submit_proba = best_model.predict_proba(test_scale)\n",
    "submit_ids = test.ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<a href='submission_file.csv.gz' target='_blank'>submission_file.csv.gz</a><br>"
      ],
      "text/plain": [
       "E:\\Code_Blooded\\LHC ML\\hadron-collider-machine-learning\\week2\\submission_file.csv.gz"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import FileLink\n",
    "utils.create_solution(submit_ids, submit_proba, filename='submission_file.csv.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
